{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMR Notebook SageMaker Custom Abalone Ring Estimator\n",
    "\n",
    "1. [Setup](#Setup)\n",
    "2. [Load the Data](#Load-the-Data)\n",
    "3. [Train the Model](#Train-the-Model)\n",
    "4. [Inference Results](#Inference-Results)\n",
    "5. [Wrap-Up](#Wrap-Up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Each EMR notebook is launched with its own Spark context (variable sc). First we need to install the Python packages that we'll use throughout the notebook. EMR notebooks come with a default set of libraries for data processing. You can see which libraries are installed on the notebook by calling the Spark Context's list_packages() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff963ab4a23e4fb3b45a514e3b0f7c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>17</td><td>application_1573168723671_0018</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-0-3-202.us-west-2.compute.internal:20888/proxy/application_1573168723671_0018/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-0-3-19.us-west-2.compute.internal:8042/node/containerlogs/container_1573168723671_0018_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                    Version\n",
      "-------------------------- -------\n",
      "beautifulsoup4             4.8.0  \n",
      "boto                       2.49.0 \n",
      "jmespath                   0.9.4  \n",
      "lxml                       4.4.1  \n",
      "mysqlclient                1.4.4  \n",
      "nltk                       3.4.5  \n",
      "nose                       1.3.4  \n",
      "numpy                      1.14.5 \n",
      "pip                        19.3.1 \n",
      "py-dateutil                2.2    \n",
      "python36-sagemaker-pyspark 1.2.4  \n",
      "pytz                       2019.2 \n",
      "PyYAML                     3.11   \n",
      "setuptools                 41.6.0 \n",
      "six                        1.12.0 \n",
      "soupsieve                  1.9.3  \n",
      "wheel                      0.33.6 \n",
      "windmill                   1.6"
     ]
    }
   ],
   "source": [
    "sc.list_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To comunicate with SageMaker we need to install notebook scoped libraries. These libraries are available only during the notebook session. After the session ends, the libraries are deleted. \n",
    "\n",
    "We install [boto3 (the AWS Python 3 SDK)](https://aws.amazon.com/sdk-for-python/) and the [high level SageMaker SDK](https://sagemaker.readthedocs.io/en/stable/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcecb48cded44f5fb3f7ae83d2fcd109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/11/7e6470f5d7d7d23fc5eaae64f8a3f4b844ca08234cc3207df027267b65c4/boto3-1.10.26-py2.py3-none-any.whl (128kB)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from boto3) (0.9.4)\n",
      "Collecting s3transfer<0.3.0,>=0.2.0\n",
      "  Using cached https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl\n",
      "Collecting botocore<1.14.0,>=1.13.26\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/93/ea2ec042794dfda186348df02c6057223a8bbc21c055124fbe3e16925441/botocore-1.13.26-py2.py3-none-any.whl (5.6MB)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Using cached https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl\n",
      "Collecting python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"\n",
      "  Using cached https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl\n",
      "Collecting urllib3<1.26,>=1.20; python_version >= \"3.4\"\n",
      "  Using cached https://files.pythonhosted.org/packages/b4/40/a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539/urllib3-1.25.7-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.26->boto3) (1.12.0)\n",
      "Installing collected packages: docutils, python-dateutil, urllib3, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.10.26 botocore-1.13.26 docutils-0.15.2 python-dateutil-2.8.0 s3transfer-0.2.1 urllib3-1.25.7\n",
      "\n",
      "Collecting sagemaker\n",
      "  Downloading https://files.pythonhosted.org/packages/5a/43/47f5f6d2ac5ff7d42bd9517e5f5b7a640abfc60f806eb37a7d3841034367/sagemaker-1.44.1.tar.gz (223kB)\n",
      "Requirement already satisfied: boto3>=1.9.213 in /mnt/tmp/1574459367751-0/lib/python3.6/site-packages (from sagemaker) (1.10.26)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib64/python3.6/site-packages (from sagemaker) (1.14.5)\n",
      "Collecting protobuf>=3.1\n",
      "  Using cached https://files.pythonhosted.org/packages/a8/52/d8d2dbff74b8bf517c42db8d44c3f9ef6555e6f5d6caddfa3f207b9143df/protobuf-3.10.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting scipy>=0.19.0\n",
      "  Using cached https://files.pythonhosted.org/packages/80/72/a26272b99220804038d8ac4aabe8383cfd969ec548695b0df258058ee919/scipy-1.3.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Processing /var/lib/livy/.cache/pip/wheels/37/42/d8/1609d310cabebc2cf60eca038fa2b0c8503412963734a6fc31/protobuf3_to_dict-0.1.5-cp36-none-any.whl\n",
      "Collecting requests<2.21,>=2.20.0\n",
      "  Using cached https://files.pythonhosted.org/packages/ff/17/5cbb026005115301a8fb2f9b0e3e8d32313142fe8b617070e7baad20554f/requests-2.20.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from boto3>=1.9.213->sagemaker) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /mnt/tmp/1574459367751-0/lib/python3.6/site-packages (from boto3>=1.9.213->sagemaker) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.26 in /mnt/tmp/1574459367751-0/lib/python3.6/site-packages (from boto3>=1.9.213->sagemaker) (1.13.26)\n",
      "Requirement already satisfied: setuptools in /mnt/tmp/1574459367751-0/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker) (41.6.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker) (1.12.0)\n",
      "Collecting urllib3<1.25,>=1.21.1\n",
      "  Using cached https://files.pythonhosted.org/packages/01/11/525b02e4acc0c747de8b6ccdab376331597c569c42ea66ab0a1dbd36eca2/urllib3-1.24.3-py2.py3-none-any.whl\n",
      "Collecting idna<2.8,>=2.5\n",
      "  Using cached https://files.pythonhosted.org/packages/4b/2a/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165/idna-2.7-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached https://files.pythonhosted.org/packages/18/b0/8146a4f8dd402f60744fa380bc73ca47303cccf8b9190fd16a827281eac2/certifi-2019.9.11-py2.py3-none-any.whl\n",
      "Collecting chardet<3.1.0,>=3.0.2\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /mnt/tmp/1574459367751-0/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.26->boto3>=1.9.213->sagemaker) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /mnt/tmp/1574459367751-0/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.26->boto3>=1.9.213->sagemaker) (2.8.0)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py): started\n",
      "  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-1.44.1-py2.py3-none-any.whl size=291523 sha256=b5842d9d169a02e6de703c5ad70ab2a18631f0adf05825e88a490290e45ba57f\n",
      "  Stored in directory: /var/lib/livy/.cache/pip/wheels/bc/12/b6/3b317a536f01ff2cbfc5dac4e9dcac786e3d37285f025b4b28\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: protobuf, scipy, protobuf3-to-dict, urllib3, idna, certifi, chardet, requests, sagemaker\n",
      "  Found existing installation: urllib3 1.25.7\n",
      "    Uninstalling urllib3-1.25.7:\n",
      "      Successfully uninstalled urllib3-1.25.7\n",
      "Successfully installed certifi-2019.9.11 chardet-3.0.4 idna-2.7 protobuf-3.10.0 protobuf3-to-dict-0.1.5 requests-2.20.1 sagemaker-1.44.1 scipy-1.3.2 urllib3-1.24.3"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"boto3\");\n",
    "sc.install_pypi_package('sagemaker');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will specify the user specific parameters. Make sure to put in the SageMaker Execution Role ARNthat you created earlier in the IAM console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d172b30007b40b5930204a3a08dd1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All necessary user parameters are entered."
     ]
    }
   ],
   "source": [
    "#define user specific parameters\n",
    "region = 'us-west-2'\n",
    "source_bucket = 's3://emr-lab-income-dataset/'\n",
    "#The IAM role that SageMaker will use to access other AWS resources.\n",
    "sagemaker_execution_role = ''\n",
    "#The number of EMR nodes to process the data.\n",
    "num_workers = 12\n",
    "\n",
    "if (region and source_bucket and sagemaker_execution_role and num_workers):\n",
    "    print('All necessary user parameters are entered.')\n",
    "else:\n",
    "    print('Please check to make sure you entered all default parameters!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f5ec1afd64429cbb7e4a3d7d570096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A SageMaker session was initiated! You are using sagemaker-us-west-2-883624334343 as your S3 bucket for intermediate files."
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "#We initiate a session for the boto3 and sagemaker APIs. The session includes information necessary to call the\n",
    "#AWS APIs, such as AWS credentials and default AWS region. For this lab we will leverage the IAM role attached to\n",
    "#the EMR notebook, so we only need to provide a region.\n",
    "boto_sess = boto3.Session(region_name=region)\n",
    "sage_sdk_session = sagemaker.Session(boto_session=boto_sess)\n",
    "bucket = sage_sdk_session.default_bucket()\n",
    "\n",
    "print('A SageMaker session was initiated! You are using {} as your S3 bucket for intermediate files.'.format(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "We will use the public abalone data set from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Abalone)\n",
    "to train and test a regression model.\n",
    "\n",
    "   Given in the dataset is the attribute name, attribute type, the measurement unit and a\n",
    "   brief description.  The number of rings is the value to predict: either\n",
    "   as a continuous value or as a classification problem.\n",
    "   \n",
    "   The age of an abalone is the number of rings in the shell + 1.5 years. Without a model researchers must cut through the abalone shell\n",
    "   and use a microscope to count the rings. Using a model to predict rings eliminates this time consuming process.\n",
    "\n",
    "\tName\t\t\tData Type\t\tMeas.\tDescription\n",
    "\t----\t\t\t---------\t\t-----\t-----------\n",
    "\tRings\t\t\tinteger\t\t\t\t\t+1.5 gives the age in years\n",
    "\tLength\t\t\tcontinuous\t\tmm\t\tLongest shell measurement\n",
    "\tDiameter\t\tcontinuous\t\tmm\t\tperpendicular to length\n",
    "\tHeight\t\t\tcontinuous\t\tmm\t\twith meat in shell\n",
    "\tWhole weight\tcontinuous\t\tgrams\twhole abalone\n",
    "\tShucked weight\tcontinuous\t\tgrams\tweight of meat\n",
    "\tViscera weight\tcontinuous\t\tgrams\tgut weight (after bleeding)\n",
    "\tShell weight\tcontinuous\t\tgrams\tafter being dried\n",
    "\tMale\t\t\tinteger\t\t\t1/0 \t1 encodes true, 0 false\n",
    "\tFemale\t\t\tinteger\t\t\t1/0 \t1 encodes true, 0 false\n",
    "\tInfant\t\t\tinteger\t\t\t1/0 \t1 encodes true, 0 false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38dd9c2595bc4b99b5e93ccd1aed7ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+--------+------+------------+--------------+--------------+------------+----+------+------+\n",
      "|Rings|Length|Diameter|Height|Whole_weight|Shucked_weight|Viscera_weight|Shell_weight|Male|Female|Infant|\n",
      "+-----+------+--------+------+------------+--------------+--------------+------------+----+------+------+\n",
      "|    9| 0.665|   0.505| 0.165|       1.349|        0.5985|        0.3175|        0.36|   0|     1|     0|\n",
      "|    7| 0.505|    0.39| 0.185|      0.6125|         0.267|         0.142|       0.172|   0|     0|     1|\n",
      "|   13| 0.575|   0.475|  0.17|       0.967|        0.3775|         0.284|       0.275|   0|     0|     1|\n",
      "|    9| 0.455|   0.355| 0.105|       0.372|         0.138|        0.0765|       0.135|   0|     0|     1|\n",
      "|   17|  0.52|   0.425| 0.155|      0.7735|         0.297|         0.123|       0.255|   1|     0|     0|\n",
      "+-----+------+--------+------+------------+--------------+--------------+------------+----+------+------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "#Download down dataset from S3\n",
    "abalone_data = spark.read.load(source_bucket + 'clean/', format='csv', inferSchema=True, header=True).repartition(num_workers)\n",
    "abalone_data.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is in Spark we can take advantage of Spark to modify and enhance our data. As an example, including all four abalone weights may be unnecessary, as they capture a lot of the same information. Let's try dropping all weight columns except for the shucked weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfdc3c20d0be4074b251abc63f2005c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+--------+------+--------------+----+------+------+\n",
      "|Rings|Length|Diameter|Height|Shucked_weight|Male|Female|Infant|\n",
      "+-----+------+--------+------+--------------+----+------+------+\n",
      "|   10|  0.73|   0.555|  0.18|        0.6555|   0|     1|     0|\n",
      "|    8| 0.435|    0.34|  0.11|        0.1495|   0|     0|     1|\n",
      "|   16| 0.565|   0.465|  0.15|         0.377|   1|     0|     0|\n",
      "|    9|  0.61|    0.47|  0.16|         0.449|   1|     0|     0|\n",
      "|   13|   0.6|    0.48| 0.175|        0.4125|   1|     0|     0|\n",
      "+-----+------+--------+------+--------------+----+------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "12"
     ]
    }
   ],
   "source": [
    "abalone_data = abalone_data.drop('Whole_weight', 'Viscera_weight', 'Shell_weight')\n",
    "abalone_data.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0275b412ad24635b0981a54347fb0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset saved in csv format to s3://sagemaker-us-west-2-883624334343/train/!\n",
      "Testing dataset saved in csv format to s3://sagemaker-us-west-2-883624334343/test/!"
     ]
    }
   ],
   "source": [
    "#Split the dataframe in to training and validation data.\n",
    "#The training will be used to refine our model.\n",
    "#The test data will be used to measure the model's accuracy.\n",
    "train_data, test_data = abalone_data.randomSplit([.75,.25])\n",
    "\n",
    "s3_train = 's3://'+ bucket + '/train/'\n",
    "s3_test = 's3://'+ bucket + '/test/'\n",
    "data_format = 'csv'\n",
    "\n",
    "#Save the data in to S3 for training by SageMaker\n",
    "train_data.write.save(s3_train, format=data_format, mode='overwrite')\n",
    "test_data.write.save(s3_test, format=data_format, mode='overwrite')\n",
    "\n",
    "print('Training dataset saved in {} format to {}!'.format(data_format, s3_train))\n",
    "print('Testing dataset saved in {} format to {}!'.format(data_format, s3_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "SageMaker contains several common built-in algorithms. For this lab you have the choice of using either the [LinearLearner](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html) or [XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) built-in algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f440057c70a24f8a8ba1a1a6a4449087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SageMaker XGBoost model will be used."
     ]
    }
   ],
   "source": [
    "#Uncomment the LinearLearner line to use the LinearLearner algorithm. \n",
    "model = 'XGBoost'\n",
    "#model = 'LinearLeaner'\n",
    "\n",
    "print('The SageMaker {} model will be used.'.format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines the hyperparameters for each algorithn. You may leave them as the defaults, but if you are interested you could try changing a few to see if it improves model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ce8ff2073243ff87f524d1bcdd5540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All model parameters have been set!"
     ]
    }
   ],
   "source": [
    "#Set the regularization weights. Increasing these will reduce how closely the model fits to the training data.\n",
    "l1 = .25\n",
    "l2 = .25\n",
    "\n",
    "#Each SageMaker algorithm has a container that SageMaker uses for training/inference.\n",
    "#These are the paths to the public container images for the SageMaker built in algorithms.\n",
    "images = {\n",
    "    'XGBoost': '433757028032.dkr.ecr.{}.amazonaws.com/xgboost:latest'.format(region),\n",
    "    'LinearLearner': '174872318107.dkr.ecr.{}.amazonaws.com/linear-learner:latest'.format(region)\n",
    "}\n",
    "\n",
    "#Hyperparameters for XGBoost algorithm\n",
    "xgboost_params = {\n",
    "    'num_round':100,\n",
    "    'objective': 'reg:linear',\n",
    "    'alpha': l1,\n",
    "    'lambda': l2\n",
    "}\n",
    "\n",
    "#Hyperparameters for LinearLearner algorithm\n",
    "linear_params = {\n",
    "    'feature_dim':len(abalone_data.columns)-1,\n",
    "    'predictor_type': 'regressor',\n",
    "    'loss': 'squared_loss',\n",
    "    'l1': l1,\n",
    "    'wd': l2\n",
    "}\n",
    "\n",
    "hyperparams = {\n",
    "    'LinearLearner': linear_params,\n",
    "    'XGBoost': xgboost_params\n",
    "}\n",
    "\n",
    "print('All model parameters have been set!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f626de6cd944b1ac1d28d02002bffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SageMaker model was constructed with parameters: {'num_round': 100, 'objective': 'reg:linear', 'alpha': 0.25, 'lambda': 0.25}."
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_name=images[model],\n",
    "    role=sagemaker_execution_role, \n",
    "    train_instance_count=1, \n",
    "    train_instance_type='ml.m5.large',\n",
    "    sagemaker_session=sage_sdk_session, \n",
    "    hyperparameters=hyperparams[model]\n",
    ")\n",
    "\n",
    "print('The SageMaker model was constructed with parameters: {}.'.format(estimator.hyperparameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we initialized the model, we can train the model by calling the fit() function. After calling fit(), SageMaker will create a training instance, train a model on the instance, save the model artifacts to S3, then take down the training instance.\n",
    "\n",
    "This usually takes about 3 minutes. \n",
    "\n",
    "(**Optional**) While you wait, you may check the model training progress through the SageMaker console by following these instructions:  \n",
    "a.\tOpen SageMaker console in AWS.  \n",
    "b.\tOn the left panel, scroll until you see ‘training jobs’ beneath the ‘Training’ section.  \n",
    "c.\tClick into the job to examine further details; wait until you see the status change to ‘Completed’.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c696b71cd8bf4982b63239e0ae8ff154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-22 22:24:19 Starting - Starting the training job...\n",
      "2019-11-22 22:24:23 Starting - Launching requested ML instances......\n",
      "2019-11-22 22:25:25 Starting - Preparing the instances for training...\n",
      "2019-11-22 22:26:15 Downloading - Downloading input data...\n",
      "2019-11-22 22:26:49 Training - Downloading the training image...\n",
      "2019-11-22 22:27:15 Uploading - Uploading generated training model\n",
      "2019-11-22 22:27:15 Completed - Training job completed\n",
      "Arguments: train\n",
      "[2019-11-22:22:27:03:INFO] Running standalone xgboost training.\n",
      "[2019-11-22:22:27:03:INFO] File size need to be processed in the node: 0.12mb. Available memory size in the node: 275.8mb\n",
      "[2019-11-22:22:27:03:INFO] Determined delimiter of CSV input is ','\n",
      "[22:27:03] S3DistributionType set as FullyReplicated\n",
      "[22:27:03] 3107x7 matrix with 21749 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\n",
      "[2019-11-22:22:27:03:INFO] Determined delimiter of CSV input is ','\n",
      "[22:27:03] S3DistributionType set as FullyReplicated\n",
      "[22:27:03] 1070x7 matrix with 7490 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[0]#011train-rmse:7.22169#011validation-rmse:7.03532\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[1]#011train-rmse:5.31486#011validation-rmse:5.16472\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[2]#011train-rmse:4.0482#011validation-rmse:3.94502\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[3]#011train-rmse:3.22296#011validation-rmse:3.20311\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[4]#011train-rmse:2.72367#011validation-rmse:2.7766\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[5]#011train-rmse:2.40558#011validation-rmse:2.56412\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[6]#011train-rmse:2.22777#011validation-rmse:2.45478\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[7]#011train-rmse:2.12335#011validation-rmse:2.40369\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[8]#011train-rmse:2.04595#011validation-rmse:2.38512\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[9]#011train-rmse:2.01362#011validation-rmse:2.3763\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10]#011train-rmse:1.98386#011validation-rmse:2.38276\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[11]#011train-rmse:1.946#011validation-rmse:2.39124\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12]#011train-rmse:1.93279#011validation-rmse:2.39627\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13]#011train-rmse:1.91893#011validation-rmse:2.39858\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[14]#011train-rmse:1.88583#011validation-rmse:2.3955\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[15]#011train-rmse:1.86145#011validation-rmse:2.40091\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[16]#011train-rmse:1.83355#011validation-rmse:2.40391\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[17]#011train-rmse:1.81664#011validation-rmse:2.41324\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 86 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18]#011train-rmse:1.79426#011validation-rmse:2.42206\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19]#011train-rmse:1.76509#011validation-rmse:2.44092\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20]#011train-rmse:1.76278#011validation-rmse:2.44128\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[21]#011train-rmse:1.75727#011validation-rmse:2.44232\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22]#011train-rmse:1.73266#011validation-rmse:2.45508\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[23]#011train-rmse:1.7135#011validation-rmse:2.45855\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[24]#011train-rmse:1.68351#011validation-rmse:2.46873\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[25]#011train-rmse:1.66398#011validation-rmse:2.47248\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[26]#011train-rmse:1.64423#011validation-rmse:2.47911\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[27]#011train-rmse:1.64309#011validation-rmse:2.47862\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[28]#011train-rmse:1.63111#011validation-rmse:2.48462\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[29]#011train-rmse:1.61102#011validation-rmse:2.48737\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[30]#011train-rmse:1.60449#011validation-rmse:2.48844\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[31]#011train-rmse:1.6009#011validation-rmse:2.48784\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[32]#011train-rmse:1.59766#011validation-rmse:2.48699\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[33]#011train-rmse:1.58136#011validation-rmse:2.49262\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[34]#011train-rmse:1.55492#011validation-rmse:2.501\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[35]#011train-rmse:1.53604#011validation-rmse:2.50338\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[36]#011train-rmse:1.52568#011validation-rmse:2.50598\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[37]#011train-rmse:1.52355#011validation-rmse:2.50649\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[38]#011train-rmse:1.51702#011validation-rmse:2.50664\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[39]#011train-rmse:1.50195#011validation-rmse:2.51213\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[40]#011train-rmse:1.48951#011validation-rmse:2.5171\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[41]#011train-rmse:1.47835#011validation-rmse:2.51733\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[42]#011train-rmse:1.46541#011validation-rmse:2.52985\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[43]#011train-rmse:1.44615#011validation-rmse:2.53476\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 86 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[44]#011train-rmse:1.42743#011validation-rmse:2.53809\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[45]#011train-rmse:1.42032#011validation-rmse:2.54126\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[46]#011train-rmse:1.41334#011validation-rmse:2.54306\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[47]#011train-rmse:1.41215#011validation-rmse:2.54394\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[48]#011train-rmse:1.40768#011validation-rmse:2.54648\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[49]#011train-rmse:1.39926#011validation-rmse:2.54868\n",
      "[22:27:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[50]#011train-rmse:1.3977#011validation-rmse:2.54971\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 80 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[51]#011train-rmse:1.38912#011validation-rmse:2.55717\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[52]#011train-rmse:1.36755#011validation-rmse:2.56078\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 80 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[53]#011train-rmse:1.36176#011validation-rmse:2.56203\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[54]#011train-rmse:1.35823#011validation-rmse:2.56126\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[55]#011train-rmse:1.34642#011validation-rmse:2.56645\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[56]#011train-rmse:1.33229#011validation-rmse:2.57283\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[57]#011train-rmse:1.30742#011validation-rmse:2.58031\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[58]#011train-rmse:1.30065#011validation-rmse:2.5806\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[59]#011train-rmse:1.29971#011validation-rmse:2.58113\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[60]#011train-rmse:1.28243#011validation-rmse:2.59416\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[61]#011train-rmse:1.26745#011validation-rmse:2.59824\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[62]#011train-rmse:1.25256#011validation-rmse:2.6034\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[63]#011train-rmse:1.24032#011validation-rmse:2.60548\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[64]#011train-rmse:1.22287#011validation-rmse:2.61746\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[65]#011train-rmse:1.21396#011validation-rmse:2.61907\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[66]#011train-rmse:1.20979#011validation-rmse:2.61931\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[67]#011train-rmse:1.20371#011validation-rmse:2.61845\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[68]#011train-rmse:1.19643#011validation-rmse:2.62315\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[69]#011train-rmse:1.19038#011validation-rmse:2.62329\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[70]#011train-rmse:1.18402#011validation-rmse:2.62508\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[71]#011train-rmse:1.18101#011validation-rmse:2.62505\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 86 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[72]#011train-rmse:1.16982#011validation-rmse:2.62689\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[73]#011train-rmse:1.16067#011validation-rmse:2.62896\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[74]#011train-rmse:1.15958#011validation-rmse:2.62879\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[75]#011train-rmse:1.15503#011validation-rmse:2.6299\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[76]#011train-rmse:1.15326#011validation-rmse:2.6302\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[77]#011train-rmse:1.14882#011validation-rmse:2.63191\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[78]#011train-rmse:1.14764#011validation-rmse:2.6313\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[79]#011train-rmse:1.14292#011validation-rmse:2.63215\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[80]#011train-rmse:1.13617#011validation-rmse:2.63307\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[81]#011train-rmse:1.12219#011validation-rmse:2.63524\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[82]#011train-rmse:1.11837#011validation-rmse:2.63699\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[83]#011train-rmse:1.11457#011validation-rmse:2.63776\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[84]#011train-rmse:1.1048#011validation-rmse:2.63876\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[85]#011train-rmse:1.0995#011validation-rmse:2.64168\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[86]#011train-rmse:1.09678#011validation-rmse:2.64131\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[87]#011train-rmse:1.0959#011validation-rmse:2.64185\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[88]#011train-rmse:1.09503#011validation-rmse:2.64171\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[89]#011train-rmse:1.09134#011validation-rmse:2.64214\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[90]#011train-rmse:1.08486#011validation-rmse:2.65306\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[91]#011train-rmse:1.0725#011validation-rmse:2.65526\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[92]#011train-rmse:1.06513#011validation-rmse:2.65788\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[93]#011train-rmse:1.04955#011validation-rmse:2.66184\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[94]#011train-rmse:1.04736#011validation-rmse:2.66211\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[95]#011train-rmse:1.03786#011validation-rmse:2.66135\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[96]#011train-rmse:1.0284#011validation-rmse:2.66427\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 86 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[97]#011train-rmse:1.021#011validation-rmse:2.66597\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[98]#011train-rmse:1.01002#011validation-rmse:2.66653\n",
      "[22:27:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[99]#011train-rmse:0.997109#011validation-rmse:2.66674\n",
      "Training seconds: 60\n",
      "Billable seconds: 60"
     ]
    }
   ],
   "source": [
    "train_channel = sagemaker.session.s3_input(s3_train + 'part', content_type='text/csv')\n",
    "estimator.fit({'train': train_channel, 'validation': valid_channel})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well did our model perform? Let's see how it does on the test data set we saved to S3 earlier. We'll use [SageMaker batch transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) to run our test data set through our model. Batch transform creates a SageMaker instance, deploys the model, runs the dataset through the model, then takes down the instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed2574e05314a84bdd72ae35b39553c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker batch transform initialized with the following parameters:\n",
      "model_name:xgboost-2019-11-22-21-57-53-853\n",
      "strategy:MultiRecord\n",
      "env:None\n",
      "output_path:s3://sagemaker-us-west-2-883624334343/inference/\n",
      "output_kms_key:None\n",
      "accept:text/csv\n",
      "assemble_with:Line\n",
      "instance_count:1\n",
      "instance_type:ml.m5.large\n",
      "volume_kms_key:None\n",
      "max_concurrent_transforms:None\n",
      "max_payload:None\n",
      "tags:None\n",
      "base_transform_job_name:None\n",
      "_current_job_name:None\n",
      "latest_transform_job:None\n",
      "_reset_output_path:False\n",
      "sagemaker_session:<sagemaker.session.Session object at 0x7f6b9fe02da0>"
     ]
    }
   ],
   "source": [
    "s3_inference = s3_train.replace('train', 'inference')\n",
    "\n",
    "transformer = estimator.transformer(\n",
    "    instance_count = 1,\n",
    "    instance_type = 'ml.m5.large',\n",
    "    strategy = 'MultiRecord',\n",
    "    output_path = s3_inference,\n",
    "    assemble_with= 'Line',\n",
    "    accept=('text/'+data_format)\n",
    ")\n",
    "\n",
    "print('SageMaker batch transform initialized with the following parameters:')\n",
    "for key in transformer.__dict__:\n",
    "    print('{}:{}'.format(key, transformer.__dict__[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transform() function initiates the SageMaker batch transform job. SageMaker will create an inference instance, run the specified test set through the model, save the results to S3, and take down the inference instance. Batch transform is a great option if you require inference for large datasets and don't need sub-second response time.\n",
    "\n",
    "This usually takes 3 minutes. \n",
    "\n",
    "(**Optional**) While you wait, you may check the batch transform progress through the SageMaker console by following these instructions:  \n",
    "a.\tOpen SageMaker console in AWS.  \n",
    "b.\tOn the left panel, scroll until you see ‘Batch transform jobs’ beneath the ‘Inference’ section.  \n",
    "c.\tClick into the job to examine further details; wait until you see the status change to ‘Completed’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3f2d3998a8404fbe3a1d205a9bebee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................!"
     ]
    }
   ],
   "source": [
    "#The test data set still contains the \"Rings\" column the model tries to predict. \n",
    "#We do not want to send this column to the model, though. We use the SageMaker\n",
    "#input_filter to filter out that column before sending to the model. We then\n",
    "#join the model output with the input so we can compare the actual Rings count\n",
    "#to the predicted count.\n",
    "transformer.transform(\n",
    "    data=s3_test,\n",
    "    content_type='text/csv',\n",
    "    split_type='Line',\n",
    "    input_filter='$[1:]',\n",
    "    join_source='Input',\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker batch transform completed and saved the model inference results to S3. Now let's pull the results in to Spark for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4cf0a75e524eb19a8fec567efb8f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+--------+------+--------------+----+------+------+---------------+\n",
      "|Rings|Length|Diameter|Height|Shucked_weight|Male|Female|Infant|Estimated_rings|\n",
      "+-----+------+--------+------+--------------+----+------+------+---------------+\n",
      "|    7| 0.505|    0.38|  0.12|        0.2595|   0|     0|     1|       8.981371|\n",
      "|    9|  0.65|     0.5|  0.16|         0.702|   0|     1|     0|       9.416534|\n",
      "|   10|  0.41|   0.315|  0.11|        0.1255|   0|     1|     0|       10.04625|\n",
      "|    8| 0.435|    0.34|  0.11|        0.1495|   0|     0|     1|       8.155085|\n",
      "|    8|  0.48|   0.355| 0.115|          0.25|   0|     0|     1|      7.1054344|\n",
      "+-----+------+--------+------+--------------+----+------+------+---------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "from copy import deepcopy\n",
    "\n",
    "#Read the schema from the initial dataset so you can apply it to the inference data.\n",
    "schema = deepcopy(abalone_data.schema)\n",
    "schema.add(\"Estimated_rings\", FloatType())\n",
    "\n",
    "#Pull down the inference data from S3\n",
    "inference_data = spark.read.load(s3_inference, format=data_format, schema=schema).repartition(num_workers)\n",
    "inference_data.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our results, we need to quantify our model's performance. We will use root mean square error (RMSE) to measure how close Estimated_rings is to the actual Rings value.\n",
    "\n",
    "RMSE is a popular way to measure how closely a regression model predicts a response. A lower RMSE indicates a closer prediction.\n",
    "\n",
    "Here is the equation for RMSE:\n",
    "\n",
    "\\begin{equation*}\n",
    "RMSE = \\sqrt{\\frac{\\sum_{i=1}^n (\\hat{y_i}-y_i)^2}{N}}\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\hat{y_i}$ is the number of predicted rings, $y_i$ is the observed number of rings, and N is the number of rows in the test data set.\n",
    "\n",
    "We'll use Spark SQL to run a SQL query on our data to calculate the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f6e266447a40fca7a917a7ac3361ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|              RMSE|\n",
      "+------------------+\n",
      "|2.6602393658357797|\n",
      "+------------------+"
     ]
    }
   ],
   "source": [
    "rings = inference_data.schema.names[0]\n",
    "predicted_rings = inference_data.schema.names[-1]\n",
    "table_name = 'inference'\n",
    "\n",
    "inference_data.registerTempTable(table_name)\n",
    "sql_rmse = 'SELECT SQRT(AVG(POWER({}-{}, 2))) AS RMSE FROM {}'.format(rings, predicted_rings, table_name)\n",
    "\n",
    "rmse_results = spark.sql(sql_rmse)\n",
    "rmse_results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-Up\n",
    "Congratulations! You processed data in Apache Spark on EMR and trained and deployed a machine learning model in Amazon SageMaker! Feel free to try different combinations of models and hyperparameters to see if you can reduce your model's RMSE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
